{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504f28ef-5e95-48e7-afd4-965319b4e916",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28c3c9d-1f8c-4d04-abf6-9a8c5c6536e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Type': 'H1', 'Content': 'Web Scraping Practice'}, {'Type': 'H2', 'Content': 'Available Products'}, {'Type': 'H2', 'Content': 'Product Table'}, {'Type': 'H2', 'Content': 'Watch This Video'}, {'Type': 'H2', 'Content': 'Contact Us'}, {'Type': 'H2', 'Content': 'Product Information'}, {'Type': 'H2', 'Content': 'Featured Products'}, {'Type': 'LI', 'Content': 'Laptop'}, {'Type': 'LI', 'Content': 'Smartphone'}, {'Type': 'LI', 'Content': 'Tablet'}, {'Type': 'LI', 'Content': 'Smartwatch'}, {'Type': 'P', 'Content': 'Welcome to the web scraping task! Use your skills to extract the required data from this page.'}, {'Type': 'P', 'Content': 'Sharp Objects'}, {'Type': 'P', 'Content': '£47.82'}, {'Type': 'P', 'Content': '✔ In stock'}, {'Type': 'P', 'Content': 'In a Dark, Dark Wood'}, {'Type': 'P', 'Content': '£19.63'}, {'Type': 'P', 'Content': '✔ In stock'}, {'Type': 'P', 'Content': 'The Past Never Ends'}, {'Type': 'P', 'Content': '£56.50'}, {'Type': 'P', 'Content': '✔ In stock'}, {'Type': 'P', 'Content': 'A Murder in Time'}, {'Type': 'P', 'Content': '£16.64'}, {'Type': 'P', 'Content': ' Out stock'}, {'Type': 'P', 'Content': 'Wireless Headphones'}, {'Type': 'P', 'Content': '$49.99'}, {'Type': 'P', 'Content': 'Available colors: Black, White, Blue'}, {'Type': 'P', 'Content': 'Smart Speaker'}, {'Type': 'P', 'Content': '$89.99'}, {'Type': 'P', 'Content': 'Available colors: Grey, Black'}, {'Type': 'P', 'Content': 'Smart Watch'}, {'Type': 'P', 'Content': '$149.99'}, {'Type': 'P', 'Content': 'Available colors: Black, Silver, Gold'}, {'Type': 'P', 'Content': '© 2024 Web Scraping Practice. All Rights Reserved.'}]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")      # To Get Request From The Web Site            \n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "li = []                                                             # The List That Will Contain Dictionaries \n",
    "\n",
    "\n",
    "# To put H1 values in the Dictionary then to the list\n",
    "Heading_1 = soup.find('h1')\n",
    "for i in Heading_1:\n",
    "    li.append({'Type':'H1' ,'Content' :Heading_1.text})\n",
    "\n",
    "# To put H2 values in the Dictionary then to the list    \n",
    "Heading_2 = soup.find_all('h2')\n",
    "for i in Heading_2:\n",
    "    li.append({'Type':'H2', 'Content':i.text})\n",
    "\n",
    "# To put li values in the Dictionary then to the list \n",
    "Lists = soup.find_all('li')\n",
    "for i in Lists:\n",
    "    for ii in i:\n",
    "        li.append({'Type':'LI', 'Content': ii.text})\n",
    "\n",
    "# To put P values in the Dictionary then to the list \n",
    "Parag = soup.find_all('p')\n",
    "for i in Parag:\n",
    "    for ii in i:\n",
    "        li.append({'Type':'P', 'Content':ii.text})\n",
    "\n",
    "print(li)\n",
    "\n",
    "# To save the Output in the CSV File\n",
    "Header = ['Type', 'Content']\n",
    "with open('Q1.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=Header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50d3d0-d579-47b5-a252-352d49727f72",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7effa10-955b-4ee3-bf0b-3238178a3b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Product': 'Laptop', 'Price': '$1000', 'In Stock': 'Yes'}, {'Product': 'Smartphone', 'Price': '$800', 'In Stock': 'No'}, {'Product': 'Tablet', 'Price': '$500', 'In Stock': 'Yes'}]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")                   # To Get Request From The Web Site \n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "li = []                                                                          # The List That Will Contain Dictionaries \n",
    "li_2  = []\n",
    "\n",
    "\n",
    "table_t = soup.find_all('tr')\n",
    "\n",
    "# To put th values in the Second List to use them as keys for the Dictionary \n",
    "th = table_t[0].find_all('th')      \n",
    "for i in th:\n",
    "    li_2.append(i.text)\n",
    "\n",
    "# To put td values in the Dictionary then to the list\n",
    "for num in range(1,len(table_t)):\n",
    "    t = table_t[num].find_all('td')\n",
    "    d = {}\n",
    "    for i in range((len(t))):\n",
    "        d[li_2[i]] = t[i].text\n",
    "    li.append(d)\n",
    "\n",
    "print(li)\n",
    "\n",
    "# To save the Output in the CSV File\n",
    "Header = ['Product', 'Price', 'In Stock']\n",
    "with open('Q2.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=Header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a3571-81a7-4be2-b90f-ac28a23a63ee",
   "metadata": {},
   "source": [
    "# Q3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffb2f59-8f30-48e3-bf1c-68593e25e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Books': [{'title': 'Sharp Objects', 'price': '£47.82', 'stock': '✔ In stock'}, {'title': 'In a Dark, Dark Wood', 'price': '£19.63', 'stock': '✔ In stock'}, {'title': 'The Past Never Ends', 'price': '£56.50', 'stock': '✔ In stock'}, {'title': 'A Murder in Time', 'price': '£16.64', 'stock': ' Out stock'}], 'Buttons': ['Add to basket', 'Add to basket', 'Add to basket', 'Add to basket']}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")                                                                          # To Get Request From The Web Site \n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "li = []                                                                                                                                 # The List That Will Contain Dictionaries \n",
    "li_2 = []\n",
    "\n",
    "Header = ['title', 'price', 'stock']\n",
    "book_2 = soup.find_all('div',style=\"text-align: center; width: 200px; border: 1px solid #ddd; padding: 10px; border-radius: 5px;\")\n",
    "\n",
    "# for books\n",
    "for num in range(len(book_2)):\n",
    "    z = book_2[num].find_all('p')\n",
    "    zz = book_2[num].find_all('button')\n",
    "    di ={}\n",
    "    for i in range(len(z)):\n",
    "        di[Header[i]]= z[i].text\n",
    "    li.append(di)\n",
    "\n",
    "    #for buttons\n",
    "    for i in zz:\n",
    "        li_2.append(i.text)\n",
    "\n",
    "d = {'Books':li,\"Buttons\":li_2}\n",
    "print(d)\n",
    "\n",
    "\n",
    "# to save the output in json file\n",
    "with open('Q3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(d, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165227ec-5acd-4a7e-a9cf-d5fefd444a3f",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9353edc8-a546-494d-800d-495b4ae85b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Label\": [\n",
      "    \"Username:\",\n",
      "    \"Password:\",\n",
      "    \"Choose an option:\",\n",
      "    \"I agree to the terms and conditions\"\n",
      "  ],\n",
      "  \"Default_Values\": [\n",
      "    \"Option 1\",\n",
      "    \"Option 2\",\n",
      "    \"Option 3\"\n",
      "  ],\n",
      "  \"input_type\": [\n",
      "    \"text\",\n",
      "    \"password\",\n",
      "    \"checkbox\",\n",
      "    \"submit\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "li_tup_1 =[]\n",
    "d ={}\n",
    "label = soup.find_all('label')\n",
    "for i in label:\n",
    "    text =i.text.replace('\\n','')\n",
    "    li_tup_1.append(text.strip())\n",
    "li_tup_1 = tuple(li_tup_1)\n",
    "\n",
    "\n",
    "Default_Values = soup.find_all('option') \n",
    "li_tup_2 =[] \n",
    "for i in Default_Values:\n",
    "    li_tup_2.append(i.text)\n",
    "li_tup_2 = tuple(li_tup_2)\n",
    "\n",
    "\n",
    "\n",
    "inp = soup.find_all('input')\n",
    "li_tup_3 =[] \n",
    "for i in inp:\n",
    "    li_tup_3.append(i.get('type'))\n",
    "li_tup_3 = tuple(li_tup_3)\n",
    "    \n",
    "  \n",
    "d = {'Label':li_tup_1,'Default_Values':li_tup_2,'input_type':li_tup_3}\n",
    "\n",
    "# to view the result of the json \n",
    "res = json.dumps(d, default=lambda x: list(x) if isinstance(x, tuple) else str(x), indent=2)\n",
    "print(res)\n",
    "\n",
    "# to save the output in json file\n",
    "with open('Q4_1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(d, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# page = requests.get(\"https://baraasalout.github.io/test.html\")\n",
    "\n",
    "# soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "# li =[]\n",
    "# li_tup =[]\n",
    "# label = soup.find_all('label')\n",
    "# for i in label:\n",
    "#     text =i.text.replace('\\n','')\n",
    "#     li_tup.append(text.strip())\n",
    "# li_tup = tuple(li_tup)\n",
    "# li.append({'Label':li_tup}) \n",
    "\n",
    "# Default_Values = soup.find_all('option') \n",
    "# li_tup =[] \n",
    "# for i in Default_Values:\n",
    "#     li_tup.append(i.text)\n",
    "# li_tup = tuple(li_tup)\n",
    "# li.append({'Default_Values':li_tup}) \n",
    "\n",
    "\n",
    "# inp = soup.find_all('input')\n",
    "# li_tup =[] \n",
    "# for i in inp:\n",
    "#     li_tup.append(i.get('type'))\n",
    "# li_tup = tuple(li_tup)\n",
    "# li.append({'input_type':li_tup})  \n",
    "    \n",
    "# print(li)  \n",
    "\n",
    "# res = json.dumps(li, default=lambda x: list(x) if isinstance(x, tuple) else str(x), indent=2)\n",
    "# print(res)\n",
    "\n",
    "# with open('Q4_2.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(li, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243448bc-0147-423d-8670-91d4fcf76bab",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0651796b-7218-450a-be38-221e162a70fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Youtube_link': 'https://www.youtube.com/watch?v=ujf9RNuBdCU'}]\n",
      "[\n",
      "  {\n",
      "    \"Youtube_link\": \"https://www.youtube.com/watch?v=ujf9RNuBdCU\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "\n",
    "v = soup.find('iframe')\n",
    "li = [{'Youtube_link': v.get('src')}]\n",
    "\n",
    "print(li)\n",
    "\n",
    "# to view the result of the json \n",
    "res = json.dumps(li, default=lambda x: list(x) if isinstance(x, tuple) else str(x), indent=2)\n",
    "print(res)\n",
    "\n",
    "# to save the output in json file\n",
    "with open('Q5.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(li, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52502c-308a-48f3-920c-1e4e07b4deeb",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe6cac9-6379-4483-b3fe-b01cfe89ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Product_1': {'ID': '101', 'Product_Name': 'Wireless Headphones', 'Price': '$49.99', 'Available colors': 'Black, White, Blue'}}, {'Product_2': {'ID': '102', 'Product_Name': 'Smart Speaker', 'Price': '$89.99', 'Available colors': 'Grey, Black'}}, {'Product_3': {'ID': '103', 'Product_Name': 'Smart Watch', 'Price': '$149.99', 'Available colors': 'Black, Silver, Gold'}}]\n",
      "[\n",
      "  {\n",
      "    \"Product_1\": {\n",
      "      \"ID\": \"101\",\n",
      "      \"Product_Name\": \"Wireless Headphones\",\n",
      "      \"Price\": \"$49.99\",\n",
      "      \"Available colors\": \"Black, White, Blue\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Product_2\": {\n",
      "      \"ID\": \"102\",\n",
      "      \"Product_Name\": \"Smart Speaker\",\n",
      "      \"Price\": \"$89.99\",\n",
      "      \"Available colors\": \"Grey, Black\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Product_3\": {\n",
      "      \"ID\": \"103\",\n",
      "      \"Product_Name\": \"Smart Watch\",\n",
      "      \"Price\": \"$149.99\",\n",
      "      \"Available colors\": \"Black, Silver, Gold\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "page = requests.get(\"https://baraasalout.github.io/test.html\")\n",
    "soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "features = soup.find_all('div',class_='product-card')\n",
    "li = []\n",
    "count =1\n",
    "for i in features:\n",
    "\n",
    "    li.append({f'Product_{count}':{'ID': i.get('data-id') , 'Product_Name':(i.find(\"p\",class_='name')).text,'Price' : (i.find(\"p\",class_='price')).text, 'Available colors' :(i.find(\"p\",class_='colors')).text[18:]}})\n",
    "    count += 1\n",
    "print(li)\n",
    "\n",
    "\n",
    "# to view the result of the json \n",
    "res = json.dumps(li, default=lambda x: list(x) if isinstance(x, tuple) else str(x), indent=2)\n",
    "print(res)\n",
    "\n",
    "# to save the output in json file\n",
    "with open('Q6_1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(li, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # another solution\n",
    "\n",
    "# page = requests.get(\"https://baraasalout.github.io/test.html\")\n",
    "# soup = BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "# features = soup.find_all('div',class_='product-card')\n",
    "# li = []\n",
    "\n",
    "# for i in features:\n",
    "\n",
    "#     li.append({'ID': i.get('data-id') , 'Product_Name':(i.find(\"p\",class_='name')).text,'Price' : (i.find(\"p\",class_='price')).text, 'Available colors' :(i.find(\"p\",class_='colors')).text[18:]})\n",
    "\n",
    "# print(li)\n",
    "\n",
    "# res = json.dumps(li, default=lambda x: list(x) if isinstance(x, tuple) else str(x), indent=2)\n",
    "# print(res)\n",
    "\n",
    "# with open('Q6_2.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(li, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d232ae-840c-441f-a21a-000f5afb7b50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95039feb-4c93-4bb1-97cf-10e7a92e760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410fa78-682b-44f8-85a4-ae9eaafb3c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf1cd1-f44b-4987-957d-e55a85a39a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d7dd3-a6ae-401a-ade9-05988612ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
